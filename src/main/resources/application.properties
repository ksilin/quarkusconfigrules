# default is 1, change that to 'all'
kafka-streams.producer.acks=1

# we are allowing some kinds of compression, disallowing any others
kafka-streams.producer.compression.type=gzip

# default is 0. This can lead to long interruptions on rebalance
kafka-streams.num.standby.replicas=3

# if kafka streams, then application-id must be defined
kafka-streams.application-id=myApp,v001

# producer.enable.idempotence if it is there at all, make sure its true
quarkus.kafka-streams.producer.enable.idempotence=false

kafka.bootstrap.servers=${BOOTSTRAP_SERVERS:localhost:19092}
quarkus.kafka-streams.bootstrap-servers=${BOOTSTRAP_SERVERS:localhost:19092}

# check for required SASL mechanism
kafka.sasl.mechanism=PLAIN

# check for security protocol
# kafka.security.protocol=SASL_SSL
kafka.security.protocol=SASL_PLAIN

# check for presence and initial string
%prod.kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
     username="USERNAME" \
     password="PASSWORD";

# check for presence and plausibility
quarkus.kafka-streams.topics=${app.source-topic},${app.target-topic}#

# setting to DEBUG required
quarkus.kafka-streams.metrics.recording.level=TRACE

# either not set, or a reasonable caching time
quarkus.kafka-streams.metadata.max.age.ms=500

# at least one, no more than 2
quarkus.kafka-streams.topic.min.insync.replicas=3

# usually broker default or 3
quarkus.kafka-streams.replicationl.factor=4

# MAYBE - check for usable log configs
quarkus.log.category."org.apache.kafka.clients".level=DEBUG
%dev.quarkus.log.level=INFO
%test.quarkus.log.level=INFO

# check for max.poll.records being within a reasonable range
quarkus.kafka-streams.consumer.max.poll.records=501
%dev.kafka-streams.consumer.max.poll.records=600

# if processign guarantee is set, it needs to be the latest version of EOS
quarkus.kafka-streams.processing.guarantee=exactly_once_v2
# commit interval is only checked in combination with EOS
%prod.kafka-streams.commit.interval.ms=150

# relation 
# too long session timeout
quarkus.kafka-streams.consumer.session.timeout.ms=600000
# too short heartbeat interval
quarkus.kafka-streams.consumer.heartbeat.interval.ms=2000


quarkus.kafka-streams.connections.max.idle.ms=300000

# error handling

# if not LogAndFail - verify WHY
%prod.kafka-streams.default.deserialization.exception.handler=com.example.UnexptectedDeserializationExceptionHandler

# if overwritten - verify WHY
%prod.kafka-streams.default.production.exception.handler=com.example.UnexpectedProductionExceptionHandler


